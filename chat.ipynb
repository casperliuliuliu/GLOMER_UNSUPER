{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\GLO_林口長庚資料集\\\\Process_2022\\\\UNSUPER\\\\raw-img\\\\cane', 'E:\\\\GLO_林口長庚資料集\\\\Process_2022\\\\UNSUPER\\\\raw-img\\\\cavallo', 'E:\\\\GLO_林口長庚資料集\\\\Process_2022\\\\UNSUPER\\\\raw-img\\\\elefante']\n",
      "4863\n",
      "2623\n",
      "1446\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing images\n",
    "image_dir = 'E:\\\\GLO_林口長庚資料集\\\\Process_2022\\\\UNSUPER\\\\raw-img'\n",
    "\n",
    "# Number of clusters (change as needed)\n",
    "num_clusters = 3\n",
    "\n",
    "# Load and preprocess images\n",
    "image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir)][:num_clusters]\n",
    "print(image_paths)\n",
    "all_image = []\n",
    "for ii in range(num_clusters):\n",
    "    temp_paths = [os.path.join(image_paths[ii], filename) for filename in os.listdir(image_paths[ii])]\n",
    "    # print(temp_paths)\n",
    "    images = [np.array(Image.open(image_path)) for image_path in temp_paths]\n",
    "    print(len(images))\n",
    "    all_image+=images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8932\n"
     ]
    }
   ],
   "source": [
    "print(len(all_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 47  47  47 ... 156 156 156]\n"
     ]
    }
   ],
   "source": [
    "print(images[0].flatten())\n",
    "# images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 640 and the array at index 7 has size 426",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m image_vectors \u001b[39m=\u001b[39m [image\u001b[39m.\u001b[39mflatten() \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images]\n\u001b[0;32m      3\u001b[0m \u001b[39m# image_vectors = [image.reshape(-1, image.shape[-1]) for image in images]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Stack image vectors into a matrix\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack(images)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Perform PCA for dimensionality reduction\u001b[39;00m\n\u001b[0;32m      8\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\VLSI\\anaconda3\\envs\\Tf-ix\\lib\\site-packages\\numpy\\core\\shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    295\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[1;32m--> 296\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 640 and the array at index 7 has size 426"
     ]
    }
   ],
   "source": [
    "# Reshape images to vectors\n",
    "image_vectors = [image.flatten() for image in images]\n",
    "# image_vectors = [image.reshape(-1, image.shape[-1]) for image in images]\n",
    "# Stack image vectors into a matrix\n",
    "X = np.vstack(images)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(X_pca)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Visualize the clustered images\n",
    "plt.figure(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m MiniBatchKMeans\n\u001b[1;32m----> 2\u001b[0m total_clusters \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_test))\n\u001b[0;32m      3\u001b[0m \u001b[39m# Initialize the K-Means model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m kmeans \u001b[39m=\u001b[39m MiniBatchKMeans(n_clusters \u001b[39m=\u001b[39m total_clusters)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "total_clusters = len(np.unique(y_test))\n",
    "# Initialize the K-Means model\n",
    "kmeans = MiniBatchKMeans(n_clusters = total_clusters)\n",
    "# Fitting the model to training set\n",
    "kmeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    plt.scatter(X_pca[labels == i, 0], X_pca[labels == i, 1], label=f'Cluster {i + 1}')\n",
    "\n",
    "plt.title('Image Clustering and Distribution')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
